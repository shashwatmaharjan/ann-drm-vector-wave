{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change fonts and specify font size\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "FONT_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "# Function to save files\n",
    "def save_file(values, file_name, file_directory):\n",
    "    \n",
    "    # Save the file as a .npy file\n",
    "    np.save(os.path.join(file_directory, file_name), values)\n",
    "    \n",
    "    print(f'Saved {file_name} to {file_directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN class\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Initialize input_layer here\n",
    "        self.input_layer = None  \n",
    "\n",
    "    # Method to build the hidden layers\n",
    "    def build_hidden_layers(self):\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        # First Convolutional Layer\n",
    "        x1 = tf.keras.layers.Conv1D(filters=600, kernel_size=95, padding='same', activation='LeakyReLU', kernel_initializer = 'glorot_normal')(self.input_layer)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        x2 = tf.keras.layers.Conv1D(filters=400, kernel_size=95, padding='same', activation='LeakyReLU', kernel_initializer = 'glorot_normal')(x1)\n",
    "        x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        x3 = tf.keras.layers.Conv1D(filters=100, kernel_size=95, padding='same', activation='LeakyReLU', kernel_initializer = 'glorot_normal')(x2)\n",
    "        x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "        return x3\n",
    "\n",
    "    # Method to build the overall model\n",
    "    def build_model(self):\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = tf.keras.layers.Input(shape=self.input_shape)\n",
    "\n",
    "        # Hidden layer\n",
    "        hidden_layer = self.build_hidden_layers()\n",
    "\n",
    "        # Output Layer\n",
    "        output_layer = tf.keras.layers.Conv1D(filters=self.output_shape[1], kernel_size=95, padding='same', activation='LeakyReLU')(hidden_layer)\n",
    "\n",
    "        # Build model\n",
    "        self.model = tf.keras.models.Model(inputs=[self.input_layer], outputs=[output_layer])\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    # Method to compile the model\n",
    "    def compile(self, optimizer, loss, evaluation_metric):\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=evaluation_metric)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    # Define method to train the model\n",
    "    def train(self, x_train, y_train, epochs, batch_size, callbacks):\n",
    "        \n",
    "        # Train model\n",
    "        self.history = self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks, validation_split=0.2)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    # Method to print summary of model\n",
    "    def summary(self):\n",
    "        \n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define directory for the normalized data\n",
    "normalized_data_directory = os.path.join(current_directory, 'data', 'normalized')\n",
    "\n",
    "# Define directory for the trained results\n",
    "trained_results_directory = os.path.join(current_directory, 'cnn', 'training_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with just the displacement data to conserve memory\n",
    "# Load the normalized training subsets for displacement data\n",
    "print('Loading the normalized training subsets for displacement data...')\n",
    "normalized_training_displacement_data = np.load(os.path.join(normalized_data_directory, 'normalized_training_displacement_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalized training subsets for force data\n",
    "print('Loading the normalized training subsets for force data...')\n",
    "normalized_training_force_data = np.load(os.path.join(normalized_data_directory, 'normalized_training_force_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the displacement and force data\n",
    "print(f'The shape of displacement data is {normalized_training_displacement_data.shape[1:]}.')\n",
    "print(f'The shape of force data is {normalized_training_force_data.shape[1:]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that remain constant during the training\n",
    "input_shape = normalized_training_displacement_data.shape[1:]\n",
    "output_shape = normalized_training_force_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the CNN class\n",
    "model = CNN(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and the model\n",
    "model.build_model()\n",
    "model.compile(optimizer = 'nadam', loss = 'mse', evaluation_metric = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "# Early stopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print('Training the model...')\n",
    "history = model.train(normalized_training_displacement_data, normalized_training_force_data, epochs = 2000, batch_size = 32, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "print('Saving the model...')\n",
    "model.model.save(os.path.join(trained_results_directory, 'model.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
