{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change fonts and specify font size\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "FONT_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to normalize the displacement and force dataset\n",
    "def normalize_data(data_to_be_normalized, training_mean, training_range):\n",
    "\n",
    "    normalized_data = (data_to_be_normalized - training_mean) / training_range\n",
    "\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save files\n",
    "def save_file(values, file_name, file_directory):\n",
    "    \n",
    "    # Save the file as a .npy file\n",
    "    np.save(os.path.join(file_directory, file_name), values)\n",
    "    \n",
    "    print(f'Saved {file_name} to {file_directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN class\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Initialize input_layer here\n",
    "        self.input_layer = None  \n",
    "\n",
    "    # Method to build the hidden layers\n",
    "    def build_hidden_layers(self):\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        # First Convolutional Layer\n",
    "        x1 = tf.keras.layers.Conv1D(filters=1, kernel_size=1, padding='same', activation='LeakyReLU')(self.input_layer)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        x2 = tf.keras.layers.Conv1D(filters=1, kernel_size=1, padding='same', activation='LeakyReLU')(x1)\n",
    "        x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "        return x2\n",
    "\n",
    "    # Method to build the overall model\n",
    "    def build_model(self):\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = tf.keras.layers.Input(shape=self.input_shape)\n",
    "\n",
    "        # Hidden layer\n",
    "        hidden_layer = self.build_hidden_layers()\n",
    "\n",
    "        # Output Layer\n",
    "        output_layer = tf.keras.layers.Conv1D(filters=1, kernel_size=1, padding='same', activation='LeakyReLU')(hidden_layer)\n",
    "\n",
    "        # Build model\n",
    "        self.model = tf.keras.models.Model(inputs=[self.input_layer], outputs=[output_layer])\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    # Method to compile the model\n",
    "    def compile(self, optimizer, loss, evaluation_metric):\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=evaluation_metric)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    # Method to print summary of model\n",
    "    def summary(self):\n",
    "        \n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define directory for the assembled data\n",
    "assembled_data_directory = os.path.join(current_directory, '..', '..', 'data', 'assembled')\n",
    "\n",
    "# Define directory for the trained results\n",
    "trained_results_directory = os.path.join(current_directory, '..', '..', 'cnn', 'training_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with just the displacement data to conserve memory\n",
    "# Load the training subsets for displacement data\n",
    "training_displacement_data = np.load(os.path.join(assembled_data_directory, 'training_displacement_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the displacement data\n",
    "print(f'The shape of displacement data is {training_displacement_data.shape[1:]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalizing parameters for displacement\n",
    "displacement_mean = np.mean(training_displacement_data)\n",
    "displacement_range = np.max(training_displacement_data) - np.min(training_displacement_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the displacement values\n",
    "normalized_training_displacement_data = normalize_data(training_displacement_data, displacement_mean, displacement_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the variables to free up memory\n",
    "del training_displacement_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training subsets for force data\n",
    "training_force_data = np.load(os.path.join(assembled_data_directory, 'training_force_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the force data\n",
    "print(f'The shape of force data is {training_force_data.shape[1:]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normalizing parameters for force\n",
    "force_mean = np.mean(training_force_data)\n",
    "force_range = np.max(training_force_data) - np.min(training_force_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the force values\n",
    "normalized_training_force_data = normalize_data(training_force_data, force_mean, force_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the variables to free up memory\n",
    "del training_force_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the normalizing parameters as a .npy file\n",
    "# Bundle everything into a single dictionary\n",
    "normalizing_parameters = {'displacement_mean': displacement_mean,\n",
    "                         'displacement_range': displacement_range,\n",
    "                         'force_mean': force_mean,\n",
    "                         'force_range': force_range}\n",
    "\n",
    "# Save the normalizing parameters as a .npy file\n",
    "save_file(normalizing_parameters, 'normalizing_parameters.npy', trained_results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that remain constant during the training\n",
    "input_shape = normalized_training_displacement_data.shape[1:]\n",
    "output_shape = normalized_training_force_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_shape, output_shape)\n",
    "model.build_model()\n",
    "model.compile(optimizer = 'nadam', loss = 'mse', evaluation_metric = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
