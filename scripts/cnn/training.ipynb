{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:20:23.421723: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-06 20:20:24.665141: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change fonts and specify font size\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "FONT_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "# Function to save files\n",
    "def save_file(values, file_name, file_directory):\n",
    "    \n",
    "    # Save the file as a .npy file\n",
    "    np.save(os.path.join(file_directory, file_name), values)\n",
    "    \n",
    "    print(f'Saved {file_name} to {file_directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN class\n",
    "class CNN():\n",
    "\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Initialize input_layer here\n",
    "        self.input_layer = None  \n",
    "\n",
    "    # Method to build the hidden layers\n",
    "    def build_hidden_layers(self):\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        # First Convolutional Layer\n",
    "        x1 = tf.keras.layers.Conv1D(filters=600, kernel_size=95, padding='same', activation='LeakyReLU', kernel_initializer = 'glorot_normal')(self.input_layer)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        x2 = tf.keras.layers.Conv1D(filters=400, kernel_size=95, padding='same', activation='LeakyReLU', kernel_initializer = 'glorot_normal')(x1)\n",
    "        x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        x3 = tf.keras.layers.Conv1D(filters=100, kernel_size=95, padding='same', activation='LeakyReLU', kernel_initializer = 'glorot_normal')(x2)\n",
    "        x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "        return x3\n",
    "\n",
    "    # Method to build the overall model\n",
    "    def build_model(self):\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = tf.keras.layers.Input(shape=self.input_shape)\n",
    "\n",
    "        # Hidden layer\n",
    "        hidden_layer = self.build_hidden_layers()\n",
    "\n",
    "        # Output Layer\n",
    "        output_layer = tf.keras.layers.Conv1D(filters=self.output_shape[1], kernel_size=95, padding='same', activation='LeakyReLU')(hidden_layer)\n",
    "\n",
    "        # Build model\n",
    "        self.model = tf.keras.models.Model(inputs=[self.input_layer], outputs=[output_layer])\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    # Method to compile the model\n",
    "    def compile(self, optimizer, loss, evaluation_metric):\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=evaluation_metric)\n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    # Define method to train the model\n",
    "    def train(self, x_train, y_train, epochs, batch_size, callbacks):\n",
    "        \n",
    "        # Train model\n",
    "        self.history = self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, callbacks=callbacks, validation_split=0.2)\n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    # Method to print summary of model\n",
    "    def summary(self):\n",
    "        \n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plots:\n",
    "    \n",
    "    def __init__(self, history, file_directory):\n",
    "\n",
    "        self.history = history\n",
    "        self.file_directory = file_directory\n",
    "\n",
    "    def loss(self):\n",
    "\n",
    "        loss_name = list(self.history.history.keys())[0]\n",
    "\n",
    "        # Training\n",
    "        loss = self.history.history[loss_name]\n",
    "        val_loss = self.history.history['val_' + loss_name]\n",
    "\n",
    "        loss_plot = plt.figure()\n",
    "        epochs = range(1, len(loss)+1)\n",
    "        plt.plot(epochs, loss, 'bo--', label = 'Training Loss', markersize = 2)\n",
    "        plt.plot(epochs, val_loss, 'go--', label = 'Validation Loss', markersize = 2)\n",
    "        plt.title('Training and Validation Loss', fontsize=FONT_SIZE)\n",
    "        plt.xlabel('Epochs', fontsize=FONT_SIZE)\n",
    "        plt.ylabel('Loss', fontsize=FONT_SIZE)\n",
    "        plt.legend(['Training Loss', 'Validation Loss'], fontsize=FONT_SIZE)\n",
    "        ax = loss_plot.gca()\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.savefig(self.file_directory + '/loss.pdf', bbox_inches='tight')\n",
    "        \n",
    "        return loss_plot\n",
    "\n",
    "    def evaluation_metric(self):\n",
    "\n",
    "        metric_name = list(self.history.history.keys())[1]\n",
    "        \n",
    "        # Training\n",
    "        metric = self.history.history[metric_name]\n",
    "        val_metric = self.history.history['val_' + metric_name]\n",
    "\n",
    "        metric_plot = plt.figure()\n",
    "        epochs = range(1, len(metric)+1)\n",
    "        plt.plot(epochs, metric, 'bo--', label = 'Training Metric', markersize = 2)\n",
    "        plt.plot(epochs, val_metric, 'go--', label = 'Validation Metric', markersize = 2)\n",
    "        plt.title('Training and Validation Evaluation Metric', fontsize=FONT_SIZE)\n",
    "        plt.xlabel('Epochs', fontsize=FONT_SIZE)\n",
    "        plt.ylabel('Evaluation Metric', fontsize=FONT_SIZE)\n",
    "        plt.legend(['Training Metric', 'Validation Metric'], fontsize=FONT_SIZE)\n",
    "        ax = metric_plot.gca()\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.savefig(self.file_directory + '/evaluation_metric.pdf', bbox_inches='tight')\n",
    "\n",
    "        return metric_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define directory for the normalized data\n",
    "normalized_data_directory = os.path.join(current_directory, '..', '..', 'data', 'normalized')\n",
    "\n",
    "# Define directory for the trained results\n",
    "trained_results_directory = os.path.join(current_directory, '..', '..', 'cnn', 'training_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ocean/projects/civ210003p/shashhhw/ann-drm-vector-wave/scripts/cnn/../../cnn/training_results'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_results_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the normalized training subsets for displacement data...\n"
     ]
    }
   ],
   "source": [
    "# Working with just the displacement data to conserve memory\n",
    "# Load the normalized training subsets for displacement data\n",
    "print('Loading the normalized training subsets for displacement data...')\n",
    "normalized_training_displacement_data = np.load(os.path.join(normalized_data_directory, 'normalized_training_displacement_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the normalized training subsets for force data...\n"
     ]
    }
   ],
   "source": [
    "# Load the normalized training subsets for force data\n",
    "print('Loading the normalized training subsets for force data...')\n",
    "normalized_training_force_data = np.load(os.path.join(normalized_data_directory, 'normalized_training_force_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of displacement data is (251, 74).\n",
      "The shape of force data is (251, 894).\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the displacement and force data\n",
    "print(f'The shape of displacement data is {normalized_training_displacement_data.shape[1:]}.')\n",
    "print(f'The shape of force data is {normalized_training_force_data.shape[1:]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables that remain constant during the training\n",
    "input_shape = normalized_training_displacement_data.shape[1:]\n",
    "output_shape = normalized_training_force_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the CNN class\n",
    "model = CNN(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:20:45.493137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31125 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.496350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31125 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:16:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.498496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31125 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3a:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.499486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 31125 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.500454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 31125 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.501372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 31125 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.502308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 31125 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2024-02-06 20:20:45.503238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 31125 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x14be89539f00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and the model\n",
    "model.build_model()\n",
    "model.compile(optimizer = 'nadam', loss = 'mse', evaluation_metric = 'mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 251, 74)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 251, 600)          4218600   \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 251, 600)          2400      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 251, 400)          22800400  \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 251, 400)          1600      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 251, 100)          3800100   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 251, 100)          400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 251, 894)          8493894   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39317394 (149.98 MB)\n",
      "Trainable params: 39315194 (149.98 MB)\n",
      "Non-trainable params: 2200 (8.59 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "# Early stopping callback\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:21:35.385042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8905\n",
      "2024-02-06 20:21:37.108880: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bcf27063d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-06 20:21:37.108906: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108910: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108913: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108916: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108924: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.108927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-02-06 20:21:37.179977: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-06 20:21:37.739056: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 65s 150ms/step - loss: 0.0428 - mae: 0.0540 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 2/2000\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 0.0713 - mae: 0.0681 - val_loss: 6.3505e-04 - val_mae: 0.0185\n",
      "Epoch 3/2000\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 0.0021 - mae: 0.0160 - val_loss: 0.0046 - val_mae: 0.0177\n",
      "Epoch 4/2000\n",
      "400/400 [==============================] - 45s 114ms/step - loss: 0.0067 - mae: 0.0209 - val_loss: 0.0061 - val_mae: 0.0204\n",
      "Epoch 5/2000\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.0101 - mae: 0.0237 - val_loss: 0.0049 - val_mae: 0.0262\n",
      "Epoch 6/2000\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.0106 - mae: 0.0259 - val_loss: 0.0044 - val_mae: 0.0175\n",
      "Epoch 7/2000\n",
      "372/400 [==========================>...] - ETA: 3s - loss: 0.0841 - mae: 0.0739"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print('Training the model...')\n",
    "history = model.train(normalized_training_displacement_data, normalized_training_force_data, epochs = 2000, batch_size = 32, callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plots(history, trained_results_directory)\n",
    "loss_plot = plot.loss()\n",
    "evaluation_metric_plot = plot.evaluation_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "print('Saving the model...')\n",
    "model.model.save(os.path.join(trained_results_directory, 'model.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
