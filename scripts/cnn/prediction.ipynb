{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io import savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change fonts and specify font size\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['mathtext.fontset'] = 'dejavuserif'\n",
    "FONT_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary functions\n",
    "# Function to save files\n",
    "def save_file(data, file_name, file_directory):\n",
    "    \n",
    "    # Save the file as a .mat file\n",
    "    savemat(os.path.join(file_directory, file_name), {'data': data})\n",
    "\n",
    "    print(f'Saved {file_name} to {file_directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to renormalize the dataset\n",
    "def renormalize_data(data_to_be_renormalized, training_mean, training_range):\n",
    "\n",
    "    renormalized_data = (data_to_be_renormalized * training_range) + training_mean\n",
    "\n",
    "    return renormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Define directory for the normalized test data\n",
    "normalized_data_directory = os.path.join(current_directory, '..', '..', 'data', 'normalized')\n",
    "\n",
    "# Define directory for the trained results\n",
    "trained_results_directory = os.path.join(current_directory, '..', '..', 'cnn', 'training_results')\n",
    "\n",
    "# Define directory for the predicted results\n",
    "predicted_results_directory = os.path.join(current_directory, '..', '..', 'cnn', 'prediction_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the normalized test subsets for displacement data...\n"
     ]
    }
   ],
   "source": [
    "# Load the normalized test subsets for displacement data\n",
    "print('Loading the normalized test subsets for displacement data...')\n",
    "normalized_test_displacement_data = np.load(os.path.join(normalized_data_directory, 'normalized_test_displacement_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the normalized test subsets for force data...\n"
     ]
    }
   ],
   "source": [
    "# Load the normalized test subsets for force data\n",
    "print('Loading the normalized test subsets for force data...')\n",
    "normalized_test_force_data = np.load(os.path.join(normalized_data_directory, 'normalized_test_force_data.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of displacement data is (251, 74).\n",
      "The shape of force data is (251, 894).\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the displacement and force data\n",
    "print(f'The shape of displacement data is {normalized_test_displacement_data.shape[1:]}.')\n",
    "print(f'The shape of force data is {normalized_test_force_data.shape[1:]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the best trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 16:32:59.163805: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-02-06 16:32:59.163830: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: swimlab-linux\n",
      "2024-02-06 16:32:59.163837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: swimlab-linux\n",
      "2024-02-06 16:32:59.163924: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.154.5\n",
      "2024-02-06 16:32:59.163949: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.146.2\n",
      "2024-02-06 16:32:59.163956: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 535.146.2 does not match DSO version 535.154.5 -- cannot find working devices in this configuration\n",
      "2024-02-06 16:32:59.164316: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load the best trained model\n",
    "print('Loading the best trained model...')\n",
    "best_trained_model = tf.keras.models.load_model(os.path.join(trained_results_directory, 'best_model.h5'), compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 251, 74)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 251, 600)          4218600   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 251, 600)         2400      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 251, 400)          22800400  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 251, 400)         1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 251, 100)          3800100   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 251, 100)         400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 251, 894)          8493894   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,317,394\n",
      "Trainable params: 39,315,194\n",
      "Non-trainable params: 2,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "print(best_trained_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions using the best trained model...\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the best trained model\n",
    "print('Making predictions using the best trained model...')\n",
    "predicted_normalized_test_force_data = best_trained_model.predict(normalized_test_displacement_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training mean and range\n",
    "normalizing_force_parameters = np.load(os.path.join(normalized_data_directory, 'normalizing_force_parameters.npy'), allow_pickle=True)\n",
    "force_mean = normalizing_force_parameters.item().get('force_mean')\n",
    "force_range = normalizing_force_parameters.item().get('force_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renormalizing the target and force data...\n"
     ]
    }
   ],
   "source": [
    "# Renormalize the target and force data\n",
    "print('Renormalizing the target and force data...')\n",
    "predicted_test_force_data = renormalize_data(predicted_normalized_test_force_data, force_mean, force_range)\n",
    "target_test_force_data = renormalize_data(normalized_test_force_data, force_mean, force_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the error\n",
    "numerator = np.sum(np.sum((np.abs(target_test_force_data - predicted_test_force_data))**2, axis=1), axis=1)\n",
    "denominator = np.sum(np.sum((np.abs(target_test_force_data))**2, axis=1), axis=1)\n",
    "error = numerator/denominator*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the error values\n",
    "# Sort the error values for Q1, Median, and Q3\n",
    "sorted_error = np.sort(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum error\n",
    "min_error_location = np.where(error == sorted_error[0])\n",
    "min_error = sorted_error[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 error\n",
    "q1_location = int(len(sorted_error)/4)\n",
    "q1_error = sorted_error[q1_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median error\n",
    "median_location = int(len(sorted_error)/2)\n",
    "median_error = sorted_error[median_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 error\n",
    "q3_location = int(3*len(sorted_error)/4)\n",
    "q3_error = sorted_error[q3_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max error\n",
    "max_error_location = np.where(error == sorted_error[-1])\n",
    "max_error = sorted_error[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum error is 0.10%.\n",
      "The Q1 error is 0.36%.\n",
      "The median error is 0.55%.\n",
      "The Q3 error is 0.88%.\n",
      "The maximum error is 5.40%.\n",
      "The mean error is 0.72%.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary of the error\n",
    "print(f'The minimum error is {min_error:.2f}%.')\n",
    "print(f'The Q1 error is {q1_error:.2f}%.')\n",
    "print(f'The median error is {median_error:.2f}%.')\n",
    "print(f'The Q3 error is {q3_error:.2f}%.')\n",
    "print(f'The maximum error is {max_error:.2f}%.')\n",
    "print(f'The mean error is {np.mean(error):.2f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the target and predicted force data...\n",
      "Saved predicted_test_force_data.mat to /media/swimlab/8e0a5339-75ae-4b57-aaae-375e5bb09ac3/ann-drm-vector-wave/scripts/cnn/../../cnn/prediction_results\n",
      "Saved target_test_force_data.mat to /media/swimlab/8e0a5339-75ae-4b57-aaae-375e5bb09ac3/ann-drm-vector-wave/scripts/cnn/../../cnn/prediction_results\n"
     ]
    }
   ],
   "source": [
    "# Save the target and predicted force data\n",
    "print('Saving the target and predicted force data...')\n",
    "save_file(predicted_test_force_data, 'predicted_test_force_data.mat', predicted_results_directory)\n",
    "save_file(target_test_force_data, 'target_test_force_data.mat', predicted_results_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
